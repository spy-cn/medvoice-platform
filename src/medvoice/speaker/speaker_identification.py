import logging
import os
import sys
import warnings
from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional, Tuple

import numpy as np
import static_ffmpeg
from funasr import AutoModel
from pydub import AudioSegment
from sklearn.metrics.pairwise import cosine_similarity

from src.medvoice.utils import audio_utils
from src.medvoice.utils.code_generator import CodeGenerator
from src.medvoice.utils.logger_utils import setup_logger
from src.medvoice.utils.mysql_connection_utils import MySQLConnectionUtil

static_ffmpeg.add_paths()

warnings.filterwarnings('ignore')

logger = setup_logger('SpeakerIdentification', level=logging.DEBUG)

project_root = Path(__file__).resolve().parents[3]  # è°ƒæ•´å±‚çº§
sys.path.append(str(project_root))

db_util = MySQLConnectionUtil(
    host='localhost',
    user='root',
    password='123456',
    database='medvoice_identity',
)


@dataclass
class SpeakerSegment:
    """è¯´è¯äººéŸ³é¢‘ç‰‡æ®µæ•°æ®ç±»"""
    start_time: float  # å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    end_time: float  # ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    text: str  # è¯†åˆ«æ–‡æœ¬
    spk_code: str  # è¯´è¯äººç¼–ç 
    spk_name: str  # è¯´è¯äººå§“å
    spk_id: str  # è¯´è¯äººID
    audio_path: str  # éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    similarity: float  # ç›¸ä¼¼åº¦å¾—åˆ†


class SpeakerIdentification:
    def __init__(self):
        self.asr_model = None
        self.sv_model = None
        self.speaker_profiles = {}  # å­˜å‚¨å·²çŸ¥è¯´è¯äººçš„å£°çº¹ç‰¹å¾
        self.speaker_names = {}  # è¯´è¯äººIDåˆ°å§“åçš„æ˜ å°„
        self.speaker_counter = 1  # è¯´è¯äººè®¡æ•°å™¨
        self.similarity_threshold = 0.7  # ç›¸ä¼¼åº¦é˜ˆå€¼
        self.temp_dir = r"/Users/spy/Documents/codes/python_code/medvoice-platform/data/audio"

    def init_models(self):
        """åˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹"""
        try:
            # åˆå§‹åŒ–ASRæ¨¡å‹ï¼ˆåŒ…å«è¯´è¯äººåˆ†ç¦»ï¼‰
            self.asr_model = AutoModel(
                model="paraformer-zh",
                vad_model="fsmn-vad",
                punc_model="ct-punc",
                spk_model="cam++",
                disable_update=True
            )
            logger.info("âœ… ASRæ¨¡å‹åŠ è½½æˆåŠŸ")

            # åˆå§‹åŒ–å£°çº¹è¯†åˆ«æ¨¡å‹
            self.sv_model = AutoModel(
                model="cam++",
                disable_update=True
            )
            logger.info("âœ… å£°çº¹è¯†åˆ«æ¨¡å‹åŠ è½½æˆåŠŸ")
            return True

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def _extract_voiceprint_embedding(self, audio_path: str) -> Optional[np.ndarray]:
        """æå–å£°çº¹åµŒå…¥å‘é‡"""
        try:
            if not os.path.exists(audio_path):
                logger.error(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
                return None

            # éŸ³é¢‘è´¨é‡æ£€æµ‹å’Œå¢å¼º
            audio_segment = AudioSegment.from_file(audio_path)
            audio_quality = audio_utils.assess_speech_quality(audio_segment)

            if audio_quality < 0.5:
                logger.debug(f"éŸ³é¢‘è´¨é‡è¾ƒä½({audio_quality:.3f})ï¼Œè¿›è¡Œå¢å¼º: {audio_path}")
                enhanced_audio = self._enhance_audio_quality(audio_segment, target_duration=2000)
                enhanced_path = audio_path.replace('.wav', '_enhanced.wav')
                enhanced_audio.export(enhanced_path, format="wav")
                audio_path = enhanced_path  # ä½¿ç”¨å¢å¼ºåçš„éŸ³é¢‘

            # æå–å£°çº¹ç‰¹å¾
            result = self.sv_model.generate(input=audio_path)

            # æ¸…ç†ä¸´æ—¶å¢å¼ºæ–‡ä»¶
            if '_enhanced' in audio_path and os.path.exists(audio_path):
                os.remove(audio_path)

            return self._process_embedding_result(result)

        except Exception as e:
            logger.error(f"æå–å£°çº¹ç‰¹å¾å¤±è´¥ {audio_path}: {e}")
            return None

    def _enhance_audio_quality(self, audio: AudioSegment, target_duration: int, max_attempts: int = 3) -> AudioSegment:
        """éŸ³é¢‘è´¨é‡å¢å¼º"""
        enhanced_audio = audio_utils.repeat_audio_pydub_exact(audio, target_duration)
        quality_score = 0.0
        for attempt in range(1, max_attempts + 1):
            quality_score = audio_utils.assess_speech_quality(enhanced_audio)
            if quality_score >= 0.5:
                logger.debug(f"âœ… éŸ³é¢‘å¢å¼ºæˆåŠŸ (ç¬¬{attempt}æ¬¡å°è¯•, è´¨é‡: {quality_score:.3f})")
                return enhanced_audio
            elif attempt < max_attempts:
                logger.debug(f"ğŸ”„ ç»§ç»­éŸ³é¢‘å¢å¼º (ç¬¬{attempt}æ¬¡å°è¯•, è´¨é‡: {quality_score:.7f})")
                enhanced_audio = audio_utils.repeat_audio_pydub_exact(enhanced_audio, target_duration * attempt)

        logger.warning(f"âš ï¸ éŸ³é¢‘å¢å¼ºæœªè¾¾ç†æƒ³è´¨é‡ (æœ€ç»ˆè´¨é‡: {quality_score:.7f})")
        return enhanced_audio

    def _process_embedding_result(self, result):

        if result and isinstance(result, list) and len(result) > 0:
            embedding = None

            if 'spk_embedding' in result[0]:
                embedding_tensor = result[0]['spk_embedding']
                embedding = embedding_tensor.cpu().numpy() if hasattr(embedding_tensor, 'cpu') else np.array(
                    embedding_tensor)

            if embedding is not None:
                # æ ‡å‡†åŒ–ç»´åº¦
                if len(embedding.shape) == 1:
                    embedding = embedding.reshape(1, -1)
                elif len(embedding.shape) == 2 and embedding.shape[0] > 1:
                    embedding = embedding[0].reshape(1, -1)

                # L2å½’ä¸€åŒ–
                embedding = embedding / np.linalg.norm(embedding)
            return embedding
        return None

    def collect_speaker_voiceprints(self,
                                    speaker_name: str, audio_paths: List[str], min_audio_count: int = 3,
                                    quality_threshold: float = 0.4) -> Optional[str]:
        """
        æ”¶é›†ç”¨æˆ·å£°çº¹ä¿¡æ¯
        :param speaker_name: è¯´è¯äººå§“å
        :param audio_paths: éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        :param min_audio_count: æœ€å°‘éœ€è¦çš„åˆæ ¼éŸ³é¢‘æ•°é‡
        :param quality_threshold: éŸ³é¢‘è´¨é‡é˜ˆå€¼
        :return: è¯´è¯äººID æˆ–Nonde
        """
        logger.info(f"å¼€å§‹ä¸º{speaker_name}æ”¶é›†å£°çº¹ä¿¡æ¯...")
        logger.info(f"å¾…å¤„ç†éŸ³é¢‘æ•°é‡ï¼š{len(audio_paths)}")
        collect_embeddings = []
        quality_scores = []

        for i, audio_path in enumerate(audio_paths):
            if not os.path.exists(audio_path):
                logger.error(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼š{audio_path}")
                continue
            try:
                # 1ã€å…ˆæ£€æŸ¥éŸ³é¢‘è´¨é‡
                need_audio_segment = AudioSegment.from_file(audio_path)
                audio_quality_score = audio_utils.assess_speech_quality(need_audio_segment)
                logger.debug(f"éŸ³é¢‘è´¨é‡é¢‘åˆ†ä¸ºï¼š{audio_quality_score}")
                # å¦‚æœéŸ³é¢‘è´¨é‡è¯„åˆ†ä¸è¾¾æ ‡ è¿›è¡Œå¢å¼º
                if audio_quality_score < quality_threshold:
                    audio = AudioSegment.from_file(audio_path)
                    repeat_audio = audio_utils.repeat_audio_pydub_exact(audio, 2000)
                    enhancement_attempt = 0
                    max_enhancement_attempts = 2
                    while enhancement_attempt <= max_enhancement_attempts:
                        quality_score = audio_utils.assess_speech_quality(repeat_audio)
                        if quality_score > quality_threshold:
                            break
                        else:
                            if enhancement_attempt < max_enhancement_attempts:
                                # å†æ¬¡å¢å¼º
                                enhancement_attempt += 1
                                logger.debug(
                                    f"ğŸ”„ å°è¯•ç¬¬ {enhancement_attempt} æ¬¡é‡æ–°å¢å¼ºä½è´¨é‡éŸ³é¢‘: {os.path.basename(audio_path)}")
                            else:
                                logger.debug(
                                    f"âš ï¸ ä½è´¨é‡éŸ³é¢‘(å·²è¾¾æœ€å¤§å¢å¼ºæ¬¡æ•°): {max_enhancement_attempts} (è´¨é‡: {quality_score})")
                                break
                else:
                    quality_scores.append(audio_quality_score)
                # 2ã€æå–å£°çº¹ä¿¡æ¯
                embedding = self._extract_voiceprint_embedding(audio_path)
                collect_embeddings.append(embedding)
            except Exception as e:
                logger.error(e)

        if len(collect_embeddings) < min_audio_count:
            logger.error(f"æœ‰æ•ˆå£°çº¹æ•°é‡ä¸è¶³ï¼Œéœ€è¦è‡³å°‘ {min_audio_count} ä¸ªï¼Œå½“å‰ {len(collect_embeddings)} ä¸ª")
            return None
        # 3ã€è´¨é‡åŠ æƒå¹³å‡èåˆ
        logger.debug("æ­£åœ¨è¿›è¡Œå£°çº¹ç‰¹å¾èåˆ...")
        combined_embedding = self._fuse_voiceprints(collect_embeddings, quality_scores)
        # 4ã€æ³¨å†Œè¯´è¯äºº
        spk_code = self._register_or_update_speaker(speaker_name, combined_embedding)
        logger.info(f"æˆåŠŸä¸º '{speaker_name}' æ³¨å†Œå£°çº¹ï¼ŒCODE: {spk_code}")
        return spk_code

    def process_audio_with_spk_diarization(self, audio_path: str, hotword: str = None) -> List[SpeakerSegment]:
        """
        å¤„ç†éŸ³é¢‘å¹¶è¿›è¡Œè¯´è¯äººåˆ†ç¦»å’Œè¯†åˆ«
        :param audio_path: è¦å¤„ç†çš„éŸ³é¢‘è·¯å¾„
        :param hotword: çƒ­è¯
        :return:
        """
        if not self.asr_model:
            logger.error("ASRæ¨¡å‹æœªåˆå§‹åŒ–")
            return []

        if not os.path.exists(audio_path):
            logger.error(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
            return []

        logger.info(f"å¼€å§‹å¤„ç†éŸ³é¢‘: {audio_path}")
        try:
            # è¯´è¯äººåˆ†ç¦»
            res = self.asr_model.generate(
                input=audio_path,
                language="auto",
                batch_size_s=300,
                hotword=hotword
            )
            if not res:
                logger.error("æ²¡æœ‰è¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³")
                return []
            # å¤„ç†æ¯ä¸€ä¸ªè¯­éŸ³ç‰‡æ®µ
            speaker_segments = []
            audio = AudioSegment.from_file(audio_path)
            for i, segment in enumerate(res):
                sentence_info_list = segment.get('sentence_info', [])
                for j, sentence_info in enumerate(sentence_info_list):
                    segment_result = self._process_single_segment(
                        sentence_info, audio, i, j
                    )
                    if segment_result:
                        speaker_segments.append(segment_result)
            # è¯†åˆ«è¯´è¯äºº
            identified_segments = self._identify_speakers_in_segments(speaker_segments)

            self._print_recognition_results(identified_segments)
            return identified_segments
        except Exception as e:
            logger.error(f"å¤„ç†éŸ³é¢‘å¤±è´¥ï¼š{e}")
            return []

        pass

    def _fuse_voiceprints(self, embeddings: List[np.ndarray], quality_scores: List[float]) -> np.ndarray:
        """
        èåˆå¤šä¸ªå£°çº¹ç‰¹å¾
        :param embeddings:
        :param quality_scores:
        :return:
        """
        # å½’ä¸€åŒ–è´¨é‡æƒé‡
        weights = np.array(quality_scores) / sum(quality_scores)

        # è®¡ç®—åŠ æƒå¹³å‡
        combined_embedding = np.average(embeddings, axis=0, weights=weights)

        # L2å½’ä¸€åŒ–
        combined_embedding = combined_embedding / np.linalg.norm(combined_embedding)

        return combined_embedding

    def _register_or_update_speaker(self, speaker_name: str, embedding: np.ndarray) -> str:
        """
        æ³¨å†Œæˆ–è€…æ›´æ–°è¯´è¯äºº
        :param speaker_name: è¯´è¯äººå§“å
        :param embedding: å£°çº¹å‘é‡
        :return: è¯´è¯äººç¼–ç 
        """
        # åˆå§‹åŒ–ç¼–ç ç”Ÿæˆå™¨å’Œæ•°æ®åº“è¿æ¥
        generator = CodeGenerator(prefix="SPK_")
        spk_code = generator.generate_code(speaker_name, use_timestamp=False)

        if not db_util.connect():
            logger.error("æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°å­˜å‚¨")
            # å¦‚æœæ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œå›é€€åˆ°æœ¬åœ°å­˜å‚¨é€»è¾‘
            return self._fallback_local_storage(speaker_name, embedding)

        try:
            # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨æ­¤è¯´è¯äººï¼ˆé€šè¿‡å§“åï¼‰
            check_sql = "SELECT spk_code, voiceprint_data FROM user_voiceprints WHERE spk_name = %s"
            result = db_util.execute_query(check_sql, (speaker_name,))

            print(f"=============:{result}")

            if result and len(result) > 0:
                # å­˜åœ¨ç°æœ‰è¯´è¯äººï¼Œè¿›è¡Œæ›´æ–°
                existing_code = result[0]['spk_code']
                old_embedding_blob = result[0]['embedding']

                # å°†æ•°æ®åº“ä¸­çš„BLOBæ•°æ®è½¬æ¢å›numpyæ•°ç»„
                old_embedding = np.frombuffer(old_embedding_blob, dtype=np.float32)

                # æŒ‡æ•°å¹³æ»‘æ›´æ–°å£°çº¹å‘é‡
                updated_embedding = 0.7 * embedding + 0.3 * old_embedding
                updated_embedding = updated_embedding / np.linalg.norm(updated_embedding)

                # å°†æ›´æ–°åçš„å‘é‡è½¬æ¢ä¸ºBLOBæ ¼å¼
                updated_embedding_blob = updated_embedding.astype(np.float32).tobytes()

                # æ›´æ–°æ•°æ®åº“
                update_sql = """
                             UPDATE user_voiceprints
                             SET voiceprint_data   = %s, \
                                 upt = NOW()
                             WHERE spk_code = %s \
                             """
                db_util.execute_update(update_sql, (updated_embedding_blob, existing_code))

                # åŒæ—¶æ›´æ–°æœ¬åœ°ç¼“å­˜
                self.speaker_profiles[existing_code] = updated_embedding
                self.speaker_names[existing_code] = speaker_name

                logger.info(f"å·²æ›´æ–°è¯´è¯äºº: {speaker_name} (CODE: {existing_code})")
                return existing_code
            else:
                # æ–°æ³¨å†Œè¯´è¯äºº
                # ç¡®ä¿ç¼–ç åœ¨æ•°æ®åº“ä¸­ä¹Ÿä¸é‡å¤
                final_spk_code = spk_code
                #self._ensure_unique_code(db_util, spk_code, speaker_name)

                # å°†å£°çº¹å‘é‡è½¬æ¢ä¸ºBLOBæ ¼å¼
                embedding_blob = embedding.astype(np.float32).tobytes()

                # æ’å…¥æ–°è®°å½•
                insert_sql = """
                             INSERT INTO user_voiceprints
                                 (spk_code, spk_name, voiceprint_data, crt, upt)
                             VALUES (%s, %s, %s, NOW(), NOW()) \
                             """
                db_util.execute_update(insert_sql, (final_spk_code, speaker_name, embedding_blob))

                # æ›´æ–°æœ¬åœ°ç¼“å­˜
                self.speaker_profiles[final_spk_code] = embedding
                self.speaker_names[final_spk_code] = speaker_name
                self.speaker_counter += 1

                logger.info(f"å·²æ³¨å†Œæ–°è¯´è¯äºº: {speaker_name} (CODE: {final_spk_code})")
                return final_spk_code

        except Exception as e:
            logger.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
            # æ•°æ®åº“æ“ä½œå¤±è´¥æ—¶å›é€€åˆ°æœ¬åœ°å­˜å‚¨
            return self._fallback_local_storage(speaker_name, embedding)


    def _fallback_local_storage(self, speaker_name: str, embedding: np.ndarray) -> str:
        """
        æ•°æ®åº“è¿æ¥å¤±è´¥æ—¶çš„å›é€€æ–¹æ¡ˆï¼Œä½¿ç”¨æœ¬åœ°å­˜å‚¨
        """
        # æ£€æŸ¥æœ¬åœ°æ˜¯å¦å·²å­˜åœ¨
        existing_code = None
        for spk_code, name in self.speaker_names.items():
            if name == speaker_name:
                existing_code = spk_code
                break

        if existing_code:
            # æ›´æ–°ç°æœ‰è¯´è¯äºº
            old_embedding = self.speaker_profiles[existing_code]
            updated_embedding = 0.7 * embedding + 0.3 * old_embedding
            updated_embedding = updated_embedding / np.linalg.norm(updated_embedding)
            self.speaker_profiles[existing_code] = updated_embedding
            logger.info(f"æœ¬åœ°å­˜å‚¨å·²æ›´æ–°è¯´è¯äºº: {speaker_name} (CODE: {existing_code})")
            return existing_code
        else:
            # æ–°æ³¨å†Œ
            spk_code = f"spk_{self.speaker_counter:03d}"
            self.speaker_counter += 1
            self.speaker_profiles[spk_code] = embedding
            self.speaker_names[spk_code] = speaker_name
            logger.info(f"æœ¬åœ°å­˜å‚¨å·²æ³¨å†Œæ–°è¯´è¯äºº: {speaker_name} (CODE: {spk_code})")
            return spk_code

    def _process_single_segment(self, sentence_info: dict, audio: AudioSegment,
                                segment_idx: int, sentence_idx: int) -> Optional[SpeakerSegment]:
        """
        å¤„ç†å•ä¸ªè¯­éŸ³ç‰‡æ®µ
        :param sentence_info:
        :param audio:
        :param segment_idx:
        :param sentence_idx:
        :return:
        """
        try:
            segments_dir = os.path.join(self.temp_dir, "segments")
            os.makedirs(segments_dir, exist_ok=True)

            text = sentence_info.get('text', '')
            start_time = sentence_info.get('start', 0)
            end_time = sentence_info.get('end', 0)
            spk_id = sentence_info.get('spk', 'æœªçŸ¥')
            logger.debug(f"è¯´è¯äººï¼š{spk_id}")
            # æå–éŸ³é¢‘ç‰‡æ®µ
            segment_audio = audio[start_time:end_time]
            # ä¿å­˜ç‰‡æ®µ
            segment_filename = f"segment_{segment_idx}_{sentence_idx}_{start_time}_{end_time}.wav"
            segment_path = os.path.join(self.temp_dir, "segments", segment_filename)
            logger.debug(f"ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ï¼š{segment_path}")
            segment_audio.export(segment_path, format="wav")
            return SpeakerSegment(
                start_time=start_time,
                end_time=end_time,
                text=text,
                spk_id=spk_id,
                spk_code="",
                spk_name="",
                audio_path=segment_path,
                similarity=0.0
            )
        except Exception as e:
            logger.error(f"å¤„ç†è¯­éŸ³ç‰‡æ®µå¤±è´¥:{e}")
            return None

    def _identify_speakers_in_segments(self, speaker_segments: List[SpeakerSegment]) -> List[SpeakerSegment]:
        """
        è¯†åˆ«ç‰‡æ®µä¸­çš„è¯´è¯äºº - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œç¡®ä¿spk_idåˆ°spk_codeçš„ä¸€å¯¹ä¸€æ˜ å°„
        æœªè¯†åˆ«çš„è¯´è¯äººå‘½åä¸ºé™Œç”Ÿäººã€é™Œç”Ÿäºº1ã€é™Œç”Ÿäºº2...
        """
        identified_segments = []
        spk_mapping = {}  # åŸå§‹speaker_id -> æ³¨å†Œspk_codeçš„æ˜ å°„
        spk_code_used = set()  # è®°å½•å·²ç»è¢«ä½¿ç”¨çš„spk_codeï¼Œé¿å…é‡å¤åˆ†é…
        spk_id_to_segments = {}  # è®°å½•æ¯ä¸ªspk_idå¯¹åº”çš„æ‰€æœ‰ç‰‡æ®µå’Œembedding
        unknown_counter = 0  # é™Œç”Ÿäººè®¡æ•°å™¨
        unknown_mapping = {}  # spk_id -> é™Œç”Ÿäººåç§°çš„æ˜ å°„

        # ç¬¬ä¸€é˜¶æ®µï¼šæ”¶é›†æ‰€æœ‰spk_idçš„ä¿¡æ¯
        for segment in speaker_segments:
            spk_id = segment.spk_id
            if spk_id not in spk_id_to_segments:
                spk_id_to_segments[spk_id] = {
                    'segments': [],
                    'embeddings': [],
                    'durations': []
                }

            query_embedding = self._extract_voiceprint_embedding(segment.audio_path)
            spk_id_to_segments[spk_id]['segments'].append(segment)
            spk_id_to_segments[spk_id]['embeddings'].append(query_embedding)
            spk_id_to_segments[spk_id]['durations'].append(segment.end_time - segment.start_time)

        # ç¬¬äºŒé˜¶æ®µï¼šä¸ºæ¯ä¸ªspk_idç¡®å®šæœ€ä½³çš„spk_code
        for spk_id, data in spk_id_to_segments.items():
            segments = data['segments']
            embeddings = data['embeddings']
            durations = data['durations']

            # ç»Ÿè®¡æ¯ä¸ªå€™é€‰spk_codeçš„å‡ºç°æ¬¡æ•°å’Œå¹³å‡ç›¸ä¼¼åº¦
            candidate_scores = {}
            valid_embeddings_count = 0  # æœ‰æ•ˆembeddingçš„æ•°é‡

            for i, (embedding, duration) in enumerate(zip(embeddings, durations)):
                if embedding is None:
                    continue

                valid_embeddings_count += 1
                dynamic_threshold = self._get_dynamic_threshold(duration)
                best_match_spk_code, best_score = self._match_against_voiceprint_library(
                    embedding, dynamic_threshold
                )

                if best_match_spk_code and best_score >= dynamic_threshold:
                    if best_match_spk_code not in candidate_scores:
                        candidate_scores[best_match_spk_code] = {
                            'count': 0,
                            'total_score': 0.0,
                            'best_score': 0.0
                        }

                    candidate_scores[best_match_spk_code]['count'] += 1
                    candidate_scores[best_match_spk_code]['total_score'] += best_score
                    candidate_scores[best_match_spk_code]['best_score'] = max(
                        candidate_scores[best_match_spk_code]['best_score'], best_score
                    )

            # é€‰æ‹©æœ€ä½³çš„spk_code
            best_spk_code = None

            if candidate_scores:
                # ç­–ç•¥ï¼šä¼˜å…ˆé€‰æ‹©å‡ºç°æ¬¡æ•°å¤šçš„ï¼Œæ¬¡æ•°ç›¸åŒæ—¶é€‰æ‹©å¹³å‡ç›¸ä¼¼åº¦é«˜çš„
                best_candidate = max(
                    candidate_scores.items(),
                    key=lambda x: (x[1]['count'], x[1]['total_score'] / x[1]['count'])
                )
                best_spk_code = best_candidate[0]

                # æ£€æŸ¥è¯¥spk_codeæ˜¯å¦å·²ç»è¢«å…¶ä»–spk_idä½¿ç”¨
                if best_spk_code in spk_code_used:
                    logger.warning(f"spk_code {best_spk_code} å·²è¢«å…¶ä»–è¯´è¯äººä½¿ç”¨ï¼Œä¸ºspk_id {spk_id} åˆ†é…é™Œç”Ÿäººåç§°")
                    best_spk_code = None
                else:
                    spk_code_used.add(best_spk_code)

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„spk_codeï¼Œåˆ†é…é™Œç”Ÿäººåç§°
            if best_spk_code is None:
                if valid_embeddings_count == 0:
                    # æ‰€æœ‰embeddingéƒ½æ— æ•ˆï¼Œåˆ†é…é™Œç”Ÿäººåç§°
                    if spk_id not in unknown_mapping:
                        if unknown_counter == 0:
                            unknown_mapping[spk_id] = "é™Œç”Ÿäºº"
                        else:
                            unknown_mapping[spk_id] = f"é™Œç”Ÿäºº{unknown_counter}"
                        unknown_counter += 1
                    best_spk_code = unknown_mapping[spk_id]
                else:
                    # æœ‰æœ‰æ•ˆembeddingä½†æœªåŒ¹é…åˆ°ä»»ä½•äººï¼Œåˆ†é…é™Œç”Ÿäººåç§°
                    if spk_id not in unknown_mapping:
                        if unknown_counter == 0:
                            unknown_mapping[spk_id] = "é™Œç”Ÿäºº"
                        else:
                            unknown_mapping[spk_id] = f"é™Œç”Ÿäºº{unknown_counter}"
                        unknown_counter += 1
                    best_spk_code = unknown_mapping[spk_id]

            spk_mapping[spk_id] = best_spk_code

        # ç¬¬ä¸‰é˜¶æ®µï¼šä¸ºæ‰€æœ‰ç‰‡æ®µåˆ†é…spk_code
        for spk_id, data in spk_id_to_segments.items():
            segments = data['segments']
            embeddings = data['embeddings']
            durations = data['durations']
            assigned_spk_code = spk_mapping[spk_id]

            for i, (segment, embedding, duration) in enumerate(zip(segments, embeddings, durations)):
                if embedding is None:
                    segment.spk_code = assigned_spk_code
                    segment.similarity = 0.0
                else:
                    dynamic_threshold = self._get_dynamic_threshold(duration)
                    best_match_spk_code, best_score = self._match_against_voiceprint_library(
                        embedding, dynamic_threshold
                    )

                    # ä½¿ç”¨ç»Ÿä¸€çš„spk_codeï¼Œä½†ä¿ç•™å½“å‰ç‰‡æ®µçš„ç›¸ä¼¼åº¦
                    segment.spk_code = assigned_spk_code
                    # å¦‚æœå½“å‰ç‰‡æ®µåŒ¹é…åˆ°çš„spk_codeä¸åˆ†é…çš„ä¸€è‡´ï¼Œä½¿ç”¨å®é™…ç›¸ä¼¼åº¦ï¼Œå¦åˆ™ä¸º0
                    if best_match_spk_code == assigned_spk_code:
                        segment.similarity = best_score
                    else:
                        segment.similarity = 0.0

                identified_segments.append(segment)

        for segment in identified_segments:
            print(segment)
            # insert_sql = """
            #              INSERT INTO audio_recognition_records (speaker_id, speaker_code, speaker_name, speech_time, \
            #                                                     speech_content, emotion, emotion_confidence, \
            #                                                     audio_file_path, \
            #                                                     audio_duration, recognition_confidence, \
            #                                                     recognition_time, \
            #                                                     crt, upt) \
            #              VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW()) \
            #              """
            #
            # params = (
            #     segment.spk_id,
            #     segment.spk_code,
            #     segment.speaker_name,
            #     segment.speech_time,
            #     segment.text or "",
            #     segment.emotion or "neutral",
            #     segment.emotion_confidence or 0.0,
            #     segment.audio_path,
            #     segment.end_time - segment.start_time,
            #     segment.similarity or 0.0,
            #     segment.audio_duration or 0.0,
            # )
            # db_util.execute_update(insert_sql, params)
        logger.debug(f"æ‰€æœ‰è¯´è¯äººçš„ID: {set(spk_id_to_segments.keys())}")
        logger.debug(f"è¯´è¯äººæ˜ å°„å…³ç³»: {spk_mapping}")
        logger.debug(f"å·²ä½¿ç”¨çš„spk_code: {spk_code_used}")
        logger.debug(f"é™Œç”Ÿäººæ˜ å°„: {unknown_mapping}")

        return identified_segments

    def _get_dynamic_threshold(self, duration: float) -> float:
        """æ ¹æ®éŸ³é¢‘æ—¶é•¿åŠ¨æ€è°ƒæ•´ç›¸ä¼¼åº¦é˜ˆå€¼"""
        base_threshold = self.similarity_threshold

        if duration < 1000:  # å°‘äº1ç§’
            return max(0.5, base_threshold - 0.2)
        elif duration < 2000:  # 1-2ç§’
            return max(0.6, base_threshold - 0.1)
        else:  # 2ç§’ä»¥ä¸Š
            return base_threshold

    def _match_against_voiceprint_library(self, query_embedding: np.ndarray,
                                          threshold: float) -> Tuple[Optional[str], float]:
        """ä¸å£°çº¹åº“è¿›è¡ŒåŒ¹é…"""
        best_match_spk_code = None
        best_score = 0.0

        for spk_code, profile_embedding in self.speaker_profiles.items():
            try:
                # ç¡®ä¿ç»´åº¦ä¸€è‡´
                if query_embedding.shape[1] != profile_embedding.shape[1]:
                    continue

                # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                similarity = cosine_similarity(query_embedding, profile_embedding)[0][0]
                logger.debug(f"è¯´è¯äººcodeï¼š{spk_code},ç›¸ä¼¼åº¦ï¼š{similarity}")
                if similarity > best_score and similarity >= threshold:
                    best_score = similarity
                    best_match_spk_code = spk_code

            except Exception as e:
                logger.error(f"ä¸è¯´è¯äºº {spk_code} æ¯”å¯¹å¤±è´¥: {e}")
                continue

        return best_match_spk_code, best_score

    def _print_recognition_results(self, segments: List[SpeakerSegment]):
        """æ‰“å°è¯†åˆ«ç»“æœ"""
        logger.debug("\n" + "=" * 60)
        logger.debug("è¯´è¯äººè¯†åˆ«ç»“æœ")
        logger.debug("=" * 60)

        for segment in segments:
            speaker_name = self.speaker_names.get(segment.spk_code, "æœªçŸ¥è¯´è¯äºº")

            if segment.spk_code != "unknown":
                logger.debug(f"âœ… è¯†åˆ«åˆ°: {speaker_name} (ç›¸ä¼¼åº¦: {segment.similarity:.3f})")
            else:
                logger.debug(f"âŒ æœªè¯†åˆ« (æœ€é«˜ç›¸ä¼¼åº¦: {segment.similarity:.3f})")
            logger.debug(f"è¯´è¯äººIDï¼š: {segment.spk_id}")
            logger.debug(f"è¯´è¯äººCODEï¼š: {segment.spk_code}")
            logger.debug(f"æ—¶é—´: {segment.start_time / 1000:.2f}s - {segment.end_time / 1000:.2f}s")
            logger.debug(f"å†…å®¹: {segment.text}")
            logger.debug(f"éŸ³é¢‘è·¯å¾„: {segment.audio_path}")
            logger.debug("-" * 40)
